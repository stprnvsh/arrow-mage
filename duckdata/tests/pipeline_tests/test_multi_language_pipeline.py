"""
Test for a multi-language data processing pipeline.
"""
import os
import sys
import pytest
import yaml
import pandas as pd
import numpy as np
import subprocess
from pipelink.crosslink import CrossLink
from pipelink.python.pipelink import run_pipeline

class TestMultiLanguagePipeline:
    """Tests for multi-language pipeline execution."""
    
    def test_full_pipeline(self, test_dir, sample_dataframe, check_language_available):
        """Test a complete pipeline with Python, R, and Julia nodes."""
        # Skip if any language is missing
        has_python = check_language_available("python")
        has_r = check_language_available("r")
        has_julia = check_language_available("julia")
        
        if not has_python:
            pytest.skip("Python is required but not available")
        
        # Create the Python script for data generation
        python_script = """
import pandas as pd
import numpy as np
from pipelink import NodeContext

def main():
    with NodeContext() as ctx:
        # Generate random data
        rows = ctx.get_param('rows', 100)
        
        # Generate random data
        df = pd.DataFrame({
            'id': range(rows),
            'value': np.random.normal(0, 1, rows),
            'category': np.random.choice(['A', 'B', 'C'], size=rows)
        })
        
        # Add a column to indicate Python processing
        df['python_step'] = True
        
        # Save output
        ctx.save_output('raw_data', df, 'Raw data generated by Python')
        
        print(f"Generated {rows} rows of data with Python")

if __name__ == "__main__":
    main()
"""
        
        # Create the R script for transformation (if R is available)
        r_script = """
# Try to load CrossLink package, or source files directly
tryCatch({
  library(CrossLink)
}, error = function(e) {
  # Look for CrossLink in various locations
  script_dir <- dirname(normalizePath(commandArgs(trailingOnly = FALSE)[grep("--file=", commandArgs(trailingOnly = FALSE), value = TRUE)][1]))
  paths <- c(
    file.path(script_dir, "..", "..", "..", "r-pipelink", "R", "crosslink.R"),
    file.path(script_dir, "..", "..", "..", "pipelink", "r", "crosslink.R")
  )
  
  for (path in paths) {
    if (file.exists(path)) {
      cat("Sourcing file:", path, "\n")
      source(path)
      break
    }
  }
})

# Initialize the node context
ctx <- node_context()

# Get input data
input_data <- get_input(ctx, "raw_data")

# Transform the data
transformed_data <- input_data
transformed_data$value_squared <- transformed_data$value^2
transformed_data$log_abs_value <- log(abs(transformed_data$value) + 1)

# Add a column to indicate R processing
transformed_data$r_step <- TRUE

# Save the results
save_output(ctx, "transformed_data", transformed_data, "Data transformed by R")

# Print summary
cat("Transformed", nrow(transformed_data), "rows with R\n")
"""
        
        # Create the Julia script for analysis (if Julia is available)
        julia_script = """
# Try to import the PipeLink package, or load modules directly if not installed
try
    # Try to import the installed package
    using PipeLink
catch e
    println("Failed to import PipeLink package, trying to load modules directly...")
    
    # Try different paths to find the modules
    script_dir = dirname(@__FILE__)
    paths = [
        joinpath(script_dir, "..", "..", "..", "jl-pipelink", "src", "CrossLink.jl"),
        joinpath(script_dir, "..", "..", "..", "jl-pipelink", "src", "PipeLinkNode.jl"),
        joinpath(script_dir, "..", "..", "..", "pipelink", "julia", "crosslink.jl"),
        joinpath(script_dir, "..", "..", "..", "pipelink", "julia", "pipelink_node.jl")
    ]
    
    module_loaded = false
    for path in paths
        if isfile(path)
            println("Including file: $path")
            include(path)
            module_loaded = true
            
            # If we find CrossLink.jl, we need to make it available to PipeLinkNode
            if occursin("CrossLink.jl", path)
                # Create global CrossLink module
                global CrossLink = Main.CrossLink
            elseif occursin("PipeLinkNode.jl", path) || occursin("pipelink_node.jl", path)
                # Import from PipeLinkNode
                global NodeContext = Main.PipeLinkNode.NodeContext
                global get_input = Main.PipeLinkNode.get_input
                global save_output = Main.PipeLinkNode.save_output
                global get_param = Main.PipeLinkNode.get_param
            end
        end
    end
    
    if !module_loaded
        error("Could not find PipeLink modules to include directly. Please install the PipeLink Julia package.")
    end
end

using DataFrames
using Statistics

function main()
    ctx = NodeContext()
    try
        # Get input data
        df = get_input(ctx, "transformed_data")
        
        # Perform analysis
        # Calculate statistics by category
        categories = unique(df.category)
        stats_rows = []
        
        for cat in categories
            cat_data = filter(row -> row.category == cat, df)
            
            # Basic statistics
            push!(stats_rows, (category=cat, statistic="count", value=nrow(cat_data)))
            push!(stats_rows, (category=cat, statistic="mean_value", value=mean(cat_data.value)))
            push!(stats_rows, (category=cat, statistic="mean_squared", value=mean(cat_data.value_squared)))
            push!(stats_rows, (category=cat, statistic="std_value", value=std(cat_data.value)))
        end
        
        # Create results DataFrame
        results = DataFrame(stats_rows)
        
        # Add a column to indicate Julia processing
        results.julia_step = fill(true, nrow(results))
        
        # Save the results
        save_output(ctx, "analysis_results", results, "Analysis results from Julia")
        
        println("Generated $(nrow(results)) statistics with Julia")
    finally
        close(ctx)
    end
end

# Run the main function
main()
"""
        
        # Create the Python final report script
        python_report_script = """
import pandas as pd
import numpy as np
from pipelink import NodeContext

def main():
    with NodeContext() as ctx:
        # Get input data
        transformed_data = ctx.get_input("transformed_data")
        analysis_results = ctx.get_input("analysis_results")
        
        # Create a report DataFrame
        report = pd.DataFrame({
            'metric': ['total_rows', 'categories', 'mean_value', 'mean_squared'],
            'value': [
                len(transformed_data),
                len(transformed_data['category'].unique()),
                transformed_data['value'].mean(),
                transformed_data['value_squared'].mean()
            ]
        })
        
        # Add a section with analysis results
        report = pd.concat([
            report,
            analysis_results.rename(columns={
                'category': 'metric',
                'statistic': 'sub_metric',
                'value': 'value'
            })
        ], ignore_index=True)
        
        # Add report metadata
        report['report_id'] = 'ML-Pipeline-Report'
        report['generated_at'] = pd.Timestamp.now().isoformat()
        
        # Save output
        ctx.save_output('final_report', report, 'Final report combining all pipeline steps')
        
        print(f"Created final report with {len(report)} metrics")

if __name__ == "__main__":
    main()
"""
        
        # Create script files
        python_path = os.path.join(test_dir, "generate_data.py")
        r_path = os.path.join(test_dir, "transform_data.R")
        julia_path = os.path.join(test_dir, "analyze_data.jl")
        report_path = os.path.join(test_dir, "create_report.py")
        
        with open(python_path, 'w') as f:
            f.write(python_script)
        
        with open(r_path, 'w') as f:
            f.write(r_script)
        
        with open(julia_path, 'w') as f:
            f.write(julia_script)
            
        with open(report_path, 'w') as f:
            f.write(python_report_script)
        
        # Create pipeline nodes based on available languages
        nodes = [
            {
                "id": "generate_data",
                "language": "python",
                "script": python_path,
                "outputs": ["raw_data"],
                "params": {
                    "rows": 100
                }
            }
        ]
        
        # Add R node if available
        if has_r:
            nodes.append({
                "id": "transform_data",
                "language": "r",
                "script": r_path,
                "inputs": ["raw_data"],
                "outputs": ["transformed_data"]
            })
        else:
            # If R is not available, add a Python fallback
            python_transform = """
import pandas as pd
import numpy as np
from pipelink import NodeContext

def main():
    with NodeContext() as ctx:
        # Get input data
        df = ctx.get_input("raw_data")
        
        # Transform the data (fallback for missing R)
        df["value_squared"] = df["value"] ** 2
        df["log_abs_value"] = np.log(np.abs(df["value"]) + 1)
        
        # Add a column to indicate Python processing
        df["r_step"] = False  # Indicate R was skipped
        df["python_fallback"] = True
        
        # Save output
        ctx.save_output("transformed_data", df, "Data transformed by Python (R fallback)")
        
        print(f"Transformed {len(df)} rows with Python (fallback for R)")

if __name__ == "__main__":
    main()
"""
            fallback_path = os.path.join(test_dir, "transform_fallback.py")
            with open(fallback_path, 'w') as f:
                f.write(python_transform)
                
            nodes.append({
                "id": "transform_data",
                "language": "python",
                "script": fallback_path,
                "inputs": ["raw_data"],
                "outputs": ["transformed_data"]
            })
        
        # Add Julia node if available
        if has_julia:
            nodes.append({
                "id": "analyze_data",
                "language": "julia",
                "script": julia_path,
                "inputs": ["transformed_data"],
                "outputs": ["analysis_results"]
            })
        else:
            # If Julia is not available, add a Python fallback
            python_analyze = """
import pandas as pd
import numpy as np
from pipelink import NodeContext

def main():
    with NodeContext() as ctx:
        # Get input data
        df = ctx.get_input("transformed_data")
        
        # Perform analysis (fallback for missing Julia)
        categories = df["category"].unique()
        stats_rows = []
        
        for cat in categories:
            cat_data = df[df["category"] == cat]
            
            stats_rows.append({
                "category": cat, 
                "statistic": "count", 
                "value": len(cat_data)
            })
            stats_rows.append({
                "category": cat, 
                "statistic": "mean_value", 
                "value": cat_data["value"].mean()
            })
            stats_rows.append({
                "category": cat, 
                "statistic": "mean_squared", 
                "value": cat_data["value_squared"].mean()
            })
            stats_rows.append({
                "category": cat, 
                "statistic": "std_value", 
                "value": cat_data["value"].std()
            })
        
        # Create results DataFrame
        results = pd.DataFrame(stats_rows)
        
        # Add a column to indicate Python fallback processing
        results["julia_step"] = False  # Indicate Julia was skipped
        results["python_fallback"] = True
        
        # Save output
        ctx.save_output("analysis_results", results, "Analysis results from Python (Julia fallback)")
        
        print(f"Generated {len(results)} statistics with Python (fallback for Julia)")

if __name__ == "__main__":
    main()
"""
            fallback_path = os.path.join(test_dir, "analyze_fallback.py")
            with open(fallback_path, 'w') as f:
                f.write(python_analyze)
                
            nodes.append({
                "id": "analyze_data",
                "language": "python",
                "script": fallback_path,
                "inputs": ["transformed_data"],
                "outputs": ["analysis_results"]
            })
        
        # Always add final Python report node
        nodes.append({
            "id": "create_report",
            "language": "python",
            "script": report_path,
            "inputs": ["transformed_data", "analysis_results"],
            "outputs": ["final_report"]
        })
        
        # Create pipeline configuration
        pipeline_config = {
            "name": "multi_language_pipeline",
            "description": "Test multi-language pipeline with Python, R, and Julia",
            "db_path": os.path.join(test_dir, "multi_language_pipeline.duckdb"),
            "working_dir": test_dir,
            "nodes": nodes
        }
        
        # Save the pipeline configuration
        config_path = os.path.join(test_dir, "multi_language_pipeline.yml")
        with open(config_path, 'w') as f:
            yaml.dump(pipeline_config, f)
        
        # Run the pipeline
        run_pipeline(config_path)
        
        # Verify the results
        cl = CrossLink(db_path=pipeline_config["db_path"])
        
        # Check raw data
        raw_data = cl.pull("raw_data")
        assert raw_data is not None
        assert "python_step" in raw_data.columns
        assert raw_data["python_step"].all()
        
        # Check transformed data
        transformed_data = cl.pull("transformed_data")
        assert transformed_data is not None
        assert "value_squared" in transformed_data.columns
        
        # Check analysis results
        analysis_results = cl.pull("analysis_results")
        assert analysis_results is not None
        assert "category" in analysis_results.columns
        assert "statistic" in analysis_results.columns
        
        # Check final report
        final_report = cl.pull("final_report")
        assert final_report is not None
        assert "metric" in final_report.columns
        assert "value" in final_report.columns
        assert "report_id" in final_report.columns
        
        cl.close() 